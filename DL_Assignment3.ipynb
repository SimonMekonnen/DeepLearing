{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY2gpX4tvB9PlCpesX6YVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonMekonnen/DeepLearing/blob/main/DL_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gK0LKb_cuknD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class DenseLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = 0.01 * torch.randn(output_size, input_size, requires_grad=True)\n",
        "        self.biases = torch.zeros(output_size, requires_grad=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return torch.mm(inputs, self.weights.t()) + self.biases"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationReLU:\n",
        "    def forward(self, inputs):\n",
        "        return torch.max(inputs, torch.tensor(0.0))\n"
      ],
      "metadata": {
        "id": "KE2qTDNMu6xr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSoftmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True)[0])\n",
        "        probabilities = exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
        "        return probabilities"
      ],
      "metadata": {
        "id": "iNxjWblhu_cO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSigmoid:\n",
        "    def forward(self, inputs):\n",
        "        return 1 / (1 + torch.exp(-inputs))"
      ],
      "metadata": {
        "id": "mP7THg9JvGmI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, input_size, neurons, output_size, activation_fn):\n",
        "        self.layers = []\n",
        "        for neuron in neurons:\n",
        "            self.layers.append(DenseLayer(input_size, neuron))\n",
        "            self.layers.append(activation_fn())\n",
        "            input_size = neuron\n",
        "        self.layers.append(DenseLayer(neurons[-1], output_size))\n",
        "        self.layers.append(ActivationSoftmax())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        for layer in self.layers:\n",
        "            inputs = layer.forward(inputs)\n",
        "        return inputs\n"
      ],
      "metadata": {
        "id": "Gx8U-K4SvLOs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(inputs, model):\n",
        "    output = inputs\n",
        "    for layer in model:\n",
        "        output = layer.forward(output)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "FtrPFnDSvOuS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    y_true_one_hot = torch.zeros_like(y_pred)\n",
        "    y_true_one_hot.scatter_(1, y_true.unsqueeze(1), 1)\n",
        "    return -torch.mean(y_true_one_hot * torch.log(y_pred) + (1 - y_true_one_hot) * torch.log(1 - y_pred))\n"
      ],
      "metadata": {
        "id": "pVlkYTi2vTpQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    pred_index = torch.argmax(y_pred, dim=1)\n",
        "    correct = pred_index == y_true\n",
        "    return correct.float().mean()\n"
      ],
      "metadata": {
        "id": "xIERuL-QvWoI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "input_size = 4\n",
        "neurons = [18, 18,18]\n",
        "output_size = 3\n",
        "samples = 10\n",
        "\n",
        "relu_model = Model(input_size, neurons, output_size, ActivationReLU)\n",
        "sigmoid_model = Model(input_size, neurons, output_size, ActivationSigmoid)\n",
        "\n",
        "input_data = torch.randn(samples, input_size)\n",
        "\n",
        "output_1 = relu_model.forward(input_data)\n",
        "output_2 = sigmoid_model.forward(input_data)\n",
        "\n",
        "y_true = torch.randint(0, 3, (samples,)).long()\n",
        "\n",
        "loss_1 = log_loss(y_true, output_1)\n",
        "accuracy_1 = accuracy(y_true, output_1)\n",
        "\n",
        "loss_2 = log_loss(y_true, output_2)\n",
        "accuracy_2 = accuracy(y_true, output_2)\n",
        "\n",
        "print(f\"ReLU Model - Loss: {loss_1.item()}, Accuracy: {accuracy_1.item()}\")\n",
        "print(f\"Sigmoid Model - Loss: {loss_2.item()}, Accuracy: {accuracy_2.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aevzRp-evb89",
        "outputId": "a0217739-e760-4819-db0b-56c78c7fd50e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReLU Model - Loss: 0.6365141272544861, Accuracy: 0.30000001192092896\n",
            "Sigmoid Model - Loss: 0.6335100531578064, Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    }
  ]
}